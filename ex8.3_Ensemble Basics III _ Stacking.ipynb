{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"ex8.3_Ensemble Basics III _ Stacking.ipynb","provenance":[],"collapsed_sections":["qMvTyj9-K75v","UxnvJySwqUnW","oDkm6zORfxkO","_bU4oXOWxk9w","DNT6cFlIx1F4","4WV3vpVRyqyQ","QbiNC2zbzS7c","laK_O9Pf0YHM","QL_OFJ18kzky","537EiRGd1NHQ","lAzUSeTyvaCZ","Fr-oEZHuy42R","G1f3BU5D7r7H","HKgN3ZS1BntG","1PWm3IaHMMCP","rFC4_rThKLql","2zhZX0eoKX3X","9RgWKvwf8PYX","Te9Hr3Cm8PYX","Xu3muYuV8quF"]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"AVG5bLhFJe6a","colab_type":"text"},"source":["# Ensemble Basics II : Boosting\n","\n","**실습 전 복습사항**\n","1. Bagging을 **얼추**안다.\n","2. Boosting을 **얼추**안다.\n","3. 사용가능한 ML 모델들이 **다수**있다.\n","4. ML의 Input과 output 구조를 명확히 이해하고 있다.\n","5. 뉴럴넷의 아이디어를 이해하고 있다.\n","6. Cross Validation의 개념을 안다.\n","\n","**실습 목표**\n","\n","1. 스태킹!\n","\n","**실습 데이터**\n","* Fashion MNIST \n","* MNIST (H.W maybe)\n","\n","\n","Q. 앙상블의 영역에 온다는 것은 어디에 더 무게추가 기울어져 있을까?\n","\n","'설명과 해석'   &   '예측 정확도'\n","\n","---------------------------\n","Rayleigh Kim<br>\n","biz.rayleigh@gmail.com\n"]},{"cell_type":"markdown","metadata":{"id":"qMvTyj9-K75v","colab_type":"text"},"source":["## 01. Stacking Example!"]},{"cell_type":"markdown","metadata":{"id":"b-jsHC321bpi","colab_type":"text"},"source":["**사실상의 모든 절차**<br>\n","**데이터셋 나누는데는 바리에이션이 엄청 많다**\n","\n","1. 데이터 셋을 A, B, C 로 나눈다.\n","    * A, B는 Training Set이라고 생각해도 좋겠다.\n","    * C는 Validation Set이라고 생각해도 괜찮겠다.\n","    * Test Set은 저 어딘가에 있다.(이것 까지 고려하면 D로도 나눠야 한다.)\n","2. 데이터셋 A에서 1계층 모델들을 훈련시킨다.\n","    * 로지스틱 리그레션, SVM, 디시젼트리 세 분류기를 학습시켰다고 해보자.\n","    * 그렇다면, 세 종류의 예측값을 뽑을 수 있겠다.\n","3. B데이터셋을 새로이 재구성한다.\n","    * 2번의 세 종류의 예측값을 Feature로 한다. Input으로 한다.\n","    * B데이터셋에 원래 있던 Target을 Y로 한다. Output으로 한다.\n","4. 재구성한 B데이터셋 위에서 2계층 모델(meta learner)을 학습시킨다.\n","    * Input이 1계층 모델들의 예측값\n","    * Output이 B데이터셋의 Y\n","5. 이제 C데이터 셋 위에서 최종검증이 가능하다.\n","    * C데이터셋도 재구성 되어야 한다.\n"," \n","\n","![모든 설명](https://i1.wp.com/blog.kaggle.com/wp-content/uploads/2017/06/image5.gif?resize=600%2C450)\n"]},{"cell_type":"markdown","metadata":{"id":"4Auy25LPejb6","colab_type":"text"},"source":["쉬운 데이터에서 일단 사용법을 익히자!\n","\n","**이쯤되면 여러분들은 이제 아이리스 전문가**\n","\n","[쉬운데이터](https://en.wikipedia.org/wiki/Iris_flower_data_set)로 간다!\n","\n","![sepal과 petal](https://www.math.umd.edu/~petersd/666/html/iris_with_labels.jpg)\n","\n","아이리스 데이터!"]},{"cell_type":"code","metadata":{"id":"N5XAT6Q_eJsu","colab_type":"code","colab":{}},"source":["import time\n","from sklearn.datasets import load_iris\n","\n","# 아이리스 데이터셋\n","iris = load_iris()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"8SYeCuh0eRgG","colab_type":"code","colab":{}},"source":["iris"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"MW-3AlpLeTgX","colab_type":"code","colab":{}},"source":["# 사용할 것 불러오고!\n","from sklearn.tree import DecisionTreeClassifier\n","from sklearn.ensemble import AdaBoostClassifier\n","from sklearn.ensemble import RandomForestClassifier\n","from sklearn.neural_network import MLPClassifier\n","from sklearn.svm import SVC\n","from sklearn.neighbors import KNeighborsClassifier\n","\n","from sklearn import metrics\n","from sklearn.model_selection import train_test_split\n","from sklearn.model_selection import KFold\n","\n","import matplotlib.pyplot as plt\n","import numpy as np"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"UxnvJySwqUnW","colab_type":"text"},"source":["### 1. 데이터셋을 나눈다\n","(테스트셋 생각 하지말고 나누어보자)\n","\n","* A, B, C 로 세토막 "]},{"cell_type":"code","metadata":{"id":"FzBytfwCfefN","colab_type":"code","colab":{}},"source":["X = iris.data\n","Y = iris.target\n","\n","A_x, B_x, A_y, B_y = train_test_split(X, Y, test_size = 0.66, shuffle = True)\n","\n","B_x, C_x, B_y, C_y = train_test_split(B_x, B_y, test_size = 0.5, shuffle = True )"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"oDkm6zORfxkO","colab_type":"text"},"source":["### 2. 1계층 모델들을 학습시킨다.\n","\n","1. DeisionTreeClassifier 하나\n","2. Logistic Regression 하나\n","3. KNeighborClassifier 하나\n","\n","**A셋 위에서 학습시킨다.**"]},{"cell_type":"code","metadata":{"id":"IvDSRt7UvsVB","colab_type":"code","colab":{}},"source":["# 사용할 모델 선언\n","lev1_DT = DecisionTreeClassifier()\n","lev1_LR = MLPClassifier(hidden_layer_sizes=(), max_iter=1000)\n","lev1_KN = KNeighborsClassifier()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"28_plSRDwE77","colab_type":"code","colab":{}},"source":["# 사용할 모델들 학습\n","\n","times = []\n","\n","times.append(time.clock())\n","\n","lev1_DT.fit(A_x, A_y)\n","\n","times.append(time.clock())\n","\n","lev1_LR.fit(A_x, A_y)\n","\n","times.append(time.clock())\n","\n","lev1_KN.fit(A_x, A_y)\n","\n","times.append(time.clock())\n","\n","for i in range(len(times)-1) :\n","    print(\"1계층 {}번째 모델 학습 소요시간 {}\".format(i, times[i+1]-times[i]))\n"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"_bU4oXOWxk9w","colab_type":"text"},"source":["### 3. B데이터셋 재구성!"]},{"cell_type":"code","metadata":{"id":"mRVD6QpKwutg","colab_type":"code","colab":{}},"source":["b1_from_1 =  lev1_DT.predict(B_x)\n","b2_from_1 =  lev1_LR.predict(B_x)\n","b3_from_1 =  lev1_KN.predict(B_x)\n","\n","B_x_new = np.column_stack((b1_from_1, b2_from_1, b3_from_1))"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"DNT6cFlIx1F4","colab_type":"text"},"source":["### 4. Meta Learner 학습!\n","\n","* 뉴럴넷을 사용하기로 한다.\n","* 히든레이어는 다음과 같이 설정한다.\n","    * n_neurons = B_x_new.shape[-1]\n","    * hidden_layer_sizes = (n_neurons, n_neurons)"]},{"cell_type":"code","metadata":{"id":"Gj8hHAazyF8z","colab_type":"code","colab":{}},"source":["n_neurons = B_x_new.shape[-1]\n","lev2_NN = MLPClassifier(hidden_layer_sizes = (n_neurons, n_neurons), max_iter=10000,\n","                       verbose = True)\n","\n","lev2_NN.fit(B_x_new, B_y)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"4WV3vpVRyqyQ","colab_type":"text"},"source":["### 5. C데이터셋 위에서 검증해보자."]},{"cell_type":"code","metadata":{"id":"zlBGFNQzywRt","colab_type":"code","colab":{}},"source":["# C 데이터셋 재구성\n","\n","c1_from_1 =  lev1_DT.predict(C_x)\n","c2_from_1 =  lev1_LR.predict(C_x)\n","c3_from_1 =  lev1_KN.predict(C_x)\n","\n","C_x_new = np.column_stack((c1_from_1, c2_from_1, c3_from_1))"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"QbiNC2zbzS7c","colab_type":"text"},"source":["#### 1계층 모델들의 성능 평가.\n","\n","* Precision : 개를 개라고 맞춘 비율\n","* Recall : 개라고 한 것 중 진짜 개의 비율"]},{"cell_type":"code","metadata":{"id":"kOWBSwAYzXtL","colab_type":"code","colab":{}},"source":["from sklearn import metrics\n","\n","predicted_y = lev1_DT.predict(C_x)\n","\n","print(\"Classification report for classifier {} : \\n {}\\n\".format(lev1_DT, metrics.classification_report(C_y, predicted_y)))\n","print(\"Classification accuracy : {}\".format(metrics.accuracy_score(C_y,predicted_y)))\n","print(\"Confusion matrix : \\n{}\".format(metrics.confusion_matrix(C_y, predicted_y).transpose()))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"YYErWQo-znoG","colab_type":"code","colab":{}},"source":["from sklearn import metrics\n","\n","predicted_y = lev1_LR.predict(C_x)\n","\n","print(\"Classification report for classifier {} : \\n {}\\n\".format(lev1_LR, metrics.classification_report(C_y, predicted_y)))\n","print(\"Classification accuracy : {}\".format(metrics.accuracy_score(C_y,predicted_y)))\n","print(\"Confusion matrix : \\n{}\".format(metrics.confusion_matrix(C_y, predicted_y).transpose()))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"r9TvC3ts0Fd7","colab_type":"code","colab":{}},"source":["from sklearn import metrics\n","\n","predicted_y = lev1_KN.predict(C_x)\n","\n","print(\"Classification report for classifier {} : \\n {}\\n\".format(lev1_KN, metrics.classification_report(C_y, predicted_y)))\n","print(\"Classification accuracy : {}\".format(metrics.accuracy_score(C_y,predicted_y)))\n","print(\"Confusion matrix : \\n{}\".format(metrics.confusion_matrix(C_y, predicted_y).transpose()))"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"laK_O9Pf0YHM","colab_type":"text"},"source":["#### 2계층 모델의 결과 평가"]},{"cell_type":"code","metadata":{"id":"AiS16fxa0c6v","colab_type":"code","colab":{}},"source":["from sklearn import metrics\n","\n","predicted_y = lev2_NN.predict(C_x_new)\n","\n","print(\"Classification report for classifier {} : \\n {}\\n\".format(lev2_NN, metrics.classification_report(C_y, predicted_y)))\n","print(\"Classification accuracy : {}\".format(metrics.accuracy_score(C_y,predicted_y)))\n","print(\"Confusion matrix : \\n{}\".format(metrics.confusion_matrix(C_y, predicted_y).transpose()))"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"QL_OFJ18kzky","colab_type":"text"},"source":["## 02. Now Your Turn!\n"]},{"cell_type":"markdown","metadata":{"id":"537EiRGd1NHQ","colab_type":"text"},"source":["### 위의 01. Stacking Example!을 그대로 따라하자.\n","\n","* 너무 쉬운 데이터셋 위에, **과도한**작업을 했으니 성능이 무너지는 것은 예사다!\n","* Discussion\n","    1. 어떤 모델이 성능이 좋았는가. \n","    2. 어떤 모델이 특히 성능이 안좋았는가.\n"]},{"cell_type":"code","metadata":{"id":"ktwSIas11gpx","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"0HwohdNI1gyJ","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"z89w73t91hDS","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"lAzUSeTyvaCZ","colab_type":"text"},"source":["## 3. Stacking More!\n"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"Fr-oEZHuy42R"},"source":["### 조금 더 어려운 데이터셋으로 간다!\n","\n","그리고, 조금 더 복잡한 개념으로 간다!\n","\n","* K-fold Cross validation을 알아야 좋다.\n","* 위의 간단한 수준의 Stacking을 이해하지 못했다면, 수업을 듣지 말고, 위의 개념을 복습하는 것이 좋다."]},{"cell_type":"code","metadata":{"id":"X4zsjsFSU5OW","colab_type":"code","colab":{}},"source":["!pip uninstall xgboost\n","!pip install xgboost\n","!pip3 install h2o4gpu"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"abkKqXYiVDun","colab_type":"code","colab":{}},"source":["import xgboost as xgb\n","\n","xgb.__version__ ## 0.82 이상이어야 한다."],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"kQ3py8Uf28G7","colab_type":"code","colab":{}},"source":["# 사용할 것 불러오고!\n","from sklearn.tree import DecisionTreeClassifier\n","from sklearn.ensemble import AdaBoostClassifier\n","from sklearn.ensemble import GradientBoostingClassifier\n","from sklearn.ensemble import RandomForestClassifier\n","from sklearn.neural_network import MLPClassifier\n","from sklearn.svm import SVC\n","from sklearn.neighbors import KNeighborsClassifier\n","from sklearn.naive_bayes import MultinomialNB\n","\n","from sklearn import metrics\n","from sklearn.model_selection import train_test_split\n","from sklearn.model_selection import KFold\n","from sklearn.model_selection import cross_val_score\n","\n","import matplotlib.pyplot as plt\n","import numpy as np\n","\n","import tensorflow as tf\n","import time\n","\n","from mlxtend.classifier import StackingCVClassifier"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"YlNGejB6373F","colab_type":"code","colab":{}},"source":["mnist = tf.keras.datasets.mnist"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"S6So8VeO5lpv","colab_type":"code","colab":{}},"source":["# mnist데이터 불러오고\n","(train_x, train_y),(test_x, test_y) = mnist.load_data()\n","\n","# 스케일링까지 한 번에!\n","train_x, test_x = train_x / 255.0, test_x / 255.0\n","\n","# reshape!\n","\n","train_x = train_x.reshape([train_x.shape[0], -1])\n","test_x = test_x.reshape([test_x.shape[0], -1])\n","\n","# shape!\n","\n","print(train_x.shape)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"G1f3BU5D7r7H","colab_type":"text"},"source":["### 스태킹 계획서\n","\n","1. 3계층으로 준비할 예정.\n","    * 1 계층 5모델\n","    * 2 계층 5모델\n","    * 3 계층 하나의 모델 ( 서로 다른 방식의 세 모델)\n","\n","2. 각 계층별로 학습데이터 재구성은 K-fold split을 이용할 것이다.\n","    * 1계층에서 데이터셋을 5개로 나눈다 A, B, C, D, E\n","    * 1계층의 5모델은 각각 A, B, C, D, E 중 하나를 제외하고서 학습시킨다.\n","    * 1계층 모델로 데이터 전체를 재구성한다.\n","    \n","    * 2계층에서는, 1계층에서 재구성된 데이터셋을 5개로 나눈다. A, B, C, D, E\n","    * 2계층의 3모델은 각각 A, B, C, D, E 중 하나를 제외하고서 학습시킨다.\n","    * 2계층 모델로 데이터를 다시 재구성한다.\n","    \n","3. 마지막 계층은 다음과 같이 진행한다.\n","    * XGBOOST를 사용한다.\n","    * 모델들의 데이터 구성은 다음과 같이 한다.\n","        1. 2계층의 예측값들로만 구성된 Feature로 학습\n","        3. 1계층과 2계층의 모든 결과를 포함한 Feature로 학습"]},{"cell_type":"markdown","metadata":{"id":"HKgN3ZS1BntG","colab_type":"text"},"source":["### Level.1"]},{"cell_type":"code","metadata":{"id":"aYF9pUTNBq9r","colab_type":"code","colab":{}},"source":["# 사용할 모델 선언\n","\n","lev1_DT = DecisionTreeClassifier(max_depth=11)\n","# lev1_KN = KNeighborsClassifier(n_neighbors = 5)  # 너무 오래 걸리는 녀석\n","lev1_NB = MultinomialNB()\n","lev1_LR = MLPClassifier(hidden_layer_sizes=(), early_stopping = True, random_state = 2019)\n","# lev1_SV = SVC() # 매우 오래 걸리는 녀석\n","# lev1_GB = GradientBoostingClassifier(n_estimators= 10, subsample = 0.9, max_depth = 4, random_state = 2019)\n","lev1_XG = xgb.XGBClassifier(n_estimators = 30, max_depth = 9,\n","                                                     **{'gpu_id' : 0,\n","                                                        'tree_method' : 'gpu_hist'},\n","                           random_state = 2019)\n","lev1_RF = RandomForestClassifier(n_estimators = 30, max_depth = 9, random_state = 2019)\n","\n","lev1_models = [lev1_DT, lev1_NB, lev1_LR, lev1_XG, lev1_RF]\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"lCS7XL66CklF","colab_type":"code","colab":{}},"source":["# 사용할 모델들 학습\n","\n","kf = KFold(n_splits = len(lev1_models) , shuffle = True, random_state = 2019)\n","\n","i = 0\n","for train_index, val_index in kf.split(train_x) :\n","    print(\"--------------------------------------------------\")\n","    print(\"1계층, {}번 째 모델 : {} 학습 시작\".format(i+1, lev1_models[i]))\n","    t1 = time.clock()\n","    lev1_models[i].fit(train_x[train_index], train_y[train_index])\n","    t2 = time.clock()\n","    print(\"{:.3f}secs 소요됨. 학습 완료\".format(t2-t1))\n","    accuracy = metrics.accuracy_score(train_y[val_index], lev1_models[i].predict(train_x[val_index]) )\n","    print(\"Validation Accuracy : {:.3f}%\".format(accuracy*100))\n","    i += 1\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"S3x6Nkhpy42c","colab":{}},"source":["# New Training Set\n","\n","t1_from_1 = lev1_DT.predict(train_x)\n","t2_from_1 = lev1_NB.predict(train_x)\n","t3_from_1 = lev1_LR.predict(train_x)\n","t4_from_1 = lev1_XG.predict(train_x)\n","t5_from_1 = lev1_RF.predict(train_x)\n","\n","train_x_from_1 = np.column_stack((t1_from_1, t2_from_1, t3_from_1, t4_from_1, t5_from_1  ))\n","\n","# New Test Set\n","\n","te1_from_1 = lev1_DT.predict(test_x)\n","te2_from_1 = lev1_NB.predict(test_x)\n","te3_from_1 = lev1_LR.predict(test_x)\n","te4_from_1 = lev1_XG.predict(test_x)\n","te5_from_1 = lev1_RF.predict(test_x)\n","\n","test_x_from_1 = np.column_stack((te1_from_1, te2_from_1, te3_from_1, te4_from_1, te5_from_1  ))"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"1PWm3IaHMMCP","colab_type":"text"},"source":["### Level.2"]},{"cell_type":"code","metadata":{"id":"QB7kXmx8MT-d","colab_type":"code","colab":{}},"source":["# 사용할 모델 선언\n","\n","lev2_DT = DecisionTreeClassifier(max_depth=8)\n","lev2_NB = MultinomialNB()\n","lev2_NN = MLPClassifier(hidden_layer_sizes=(8,8), early_stopping = True, random_state = 2019)\n","lev2_XG = xgb.XGBClassifier(n_estimators = 20, max_depth = 6,\n","                                                     **{'gpu_id' : 0,\n","                                                        'tree_method' : 'gpu_hist'},\n","                            random_state = 2019)\n","lev2_RF = RandomForestClassifier(n_estimators = 20, max_depth = 6, random_state = 2019)\n","\n","lev2_models = [lev2_DT, lev2_NB, lev2_NN, lev2_XG, lev2_RF]\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"SVXqhtsOM6GR","colab_type":"code","colab":{}},"source":["# 사용할 모델들 학습\n","\n","kf = KFold(n_splits = len(lev2_models) , shuffle = True, random_state = 2020)\n","\n","i = 0\n","for train_index, val_index in kf.split(train_x_from_1) :\n","    print(\"--------------------------------------------------\")\n","    print(\"2계층, {}번 째 모델 : {} 학습 시작\".format(i+1, lev2_models[i]))\n","    t1 = time.clock()\n","    lev2_models[i].fit(train_x_from_1[train_index], train_y[train_index])\n","    t2 = time.clock()\n","    print(\"{:.3f}secs 소요됨. 학습 완료\".format(t2-t1))\n","    accuracy = metrics.accuracy_score(train_y[val_index], lev2_models[i].predict(train_x_from_1[val_index]) )\n","    print(\"Validation Accuracy : {:.3f}%\".format(accuracy*100))\n","    i += 1\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"ha2HtLKfNDbg","colab_type":"code","colab":{}},"source":["# New Training Set\n","\n","t1_from_2 = lev2_DT.predict(train_x_from_1)\n","t2_from_2 = lev2_NB.predict(train_x_from_1)\n","t3_from_2 = lev2_NN.predict(train_x_from_1)\n","t4_from_2 = lev2_XG.predict(train_x_from_1)\n","t5_from_2 = lev2_RF.predict(train_x_from_1)\n","\n","train_x_from_2 = np.column_stack((t1_from_2, t2_from_2, t3_from_2, t4_from_2, t5_from_2  ))\n","\n","# New Test Set\n","\n","te1_from_2 = lev2_DT.predict(test_x_from_1)\n","te2_from_2 = lev2_NB.predict(test_x_from_1)\n","te3_from_2 = lev2_NN.predict(test_x_from_1)\n","te4_from_2 = lev2_XG.predict(test_x_from_1)\n","te5_from_2 = lev2_RF.predict(test_x_from_1)\n","\n","test_x_from_2 = np.column_stack((te1_from_2, te2_from_2, te3_from_2, te4_from_2, te5_from_2  ))\n","\n"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"rFC4_rThKLql","colab_type":"text"},"source":["### Level.3 -1\n","\n","2 계층의 데이터만으로 진행한다."]},{"cell_type":"code","metadata":{"id":"hzOmvS2SKnAD","colab_type":"code","colab":{}},"source":["lev3_XG1 = xgb.XGBClassifier(n_estimators = 20, max_depth = 6,\n","                            **{'gpu_id' : 0, 'tree_method' : 'gpu_hist'},\n","                              verbose = True,\n","                           random_state = 2019)\n","\n","lev3_XG1.fit(train_x_from_2, train_y)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"qFxbiSYELGQW","colab_type":"code","colab":{}},"source":["from sklearn import metrics\n","\n","predicted_y = lev3_XG1.predict(test_x_from_2)\n","\n","print(\"Classification report for classifier {} : \\n {}\\n\".format(lev3_XG1, metrics.classification_report(test_y, predicted_y)))\n","print(\"Classification accuracy : {}\".format(metrics.accuracy_score(test_y,predicted_y)))\n","print(\"Confusion matrix : \\n{}\".format(metrics.confusion_matrix(test_y, predicted_y).transpose()))"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"2zhZX0eoKX3X","colab_type":"text"},"source":["### Level.3 -2\n","\n","2 계층의 데이터와, 1계층의 3, 4번 컬럼도 가져온다."]},{"cell_type":"code","metadata":{"id":"UHZ3GftiOeZN","colab_type":"code","colab":{}},"source":["train_x_from_12 = np.column_stack((train_x_from_1,train_x_from_2))\n","test_x_from_12 = np.column_stack((test_x_from_1,test_x_from_2))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"DROuJWorO8AR","colab_type":"code","colab":{}},"source":["lev3_XG2 = xgb.XGBClassifier(n_estimators = 40, max_depth = 8,\n","                            **{'gpu_id' : 0, 'tree_method' : 'gpu_hist'},\n","                              verbose = True,\n","                           random_state = 2019)\n","\n","lev3_XG2.fit(train_x_from_12, train_y)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"hy13jzJ2PDjG","colab_type":"code","colab":{}},"source":["from sklearn import metrics\n","\n","predicted_y = lev3_XG2.predict(test_x_from_12)\n","\n","print(\"Classification report for classifier {} : \\n {}\\n\".format(lev3_XG2, metrics.classification_report(test_y, predicted_y)))\n","print(\"Classification accuracy : {}\".format(metrics.accuracy_score(test_y,predicted_y)))\n","print(\"Confusion matrix : \\n{}\".format(metrics.confusion_matrix(test_y, predicted_y).transpose()))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"zwqHLpJhRDoP","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"9RgWKvwf8PYX"},"source":["## 04. Now Your Turn Again!\n"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"Te9Hr3Cm8PYX"},"source":["### 위의 03. Stacking More!를 그대로 따라하자.\n"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"3SQTS30z8PYY","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"9qrDA4to8PYa","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"CuIHipDs8PYb","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Xu3muYuV8quF","colab_type":"text"},"source":["## 5. Competition on Fashion MNIST"]},{"cell_type":"markdown","metadata":{"id":"uEMGA9Dl79jb","colab_type":"text"},"source":["아무 제한 없다. 배운 것 전부 사용하여 성능을 올려라!"]},{"cell_type":"code","metadata":{"id":"NegeEDpC9cz-","colab_type":"code","colab":{}},"source":["import tensorflow as tf\n","import random as rd\n","import matplotlib.pyplot as plt\n","\n","(train_x, train_y), (test_x, test_y) = tf.keras.datasets.fashion_mnist.load_data()\n","\n","labels = {0 : 'T-shirt/top',  \n","1 : 'Trouser'  ,\n","2 : 'Pullover'  ,\n","3 : 'Dress' , \n","4 : 'Coat'  ,\n","5 : 'Sandal'  ,\n","6 : 'Shirt'  ,\n","7 : 'Sneaker'  ,\n","8 : 'Bag'  ,\n","9 : 'Ankle boot'}"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"6D7UEjow9hIB","colab_type":"code","colab":{}},"source":["'''\n","Ctrl+Enter를 이용하여\n","반복 실행 해보자!\n","'''\n","\n","id = rd.randrange(0,10000)\n","\n","print('id = {}'.format(id))\n","print('다음 그림은 {} 입니다.'.format(labels[test_y[id]]))\n","plt.imshow(test_x[id])\n","plt.show()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"PstsSKi6-pyd","colab_type":"code","colab":{}},"source":["# reshape!\n","train_x_flatten = train_x.reshape([train_x.shape[0],-1])\n","test_x_flatten = test_x.reshape([test_x.shape[0],-1])\n","\n","print(train_x_flatten.shape, train_y.shape)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"dF5_0rNk-xLh","colab_type":"code","colab":{}},"source":["## Your Code"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"xh_tzljQ-zYd","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"ro-ax5LU-HCM","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}